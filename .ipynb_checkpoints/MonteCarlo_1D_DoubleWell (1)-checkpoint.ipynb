{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Monte Carlo\n",
    "\n",
    "## 1.) Theoretical considerations & Model\n",
    "\n",
    "Let us consider a one-dimensional potential well (double well) described by the function\n",
    "\n",
    "$$U(x) = \\frac{D_0}{a^4} \\left( (x^2 - a^2)^2 + lx\\right),$$\n",
    "\n",
    "where $D_0$ is a measure of the depth of the well, while $a$ describes its width and $l$ its asymmetry. There is a one point particle defined by its position $x$ residing in the well. Let us couple the particle to a thermostat of a fixed temperature $1/\\beta$. The particle coupled to the thermostat does not conserve energy, as it is being constantly exchanged with the thermostat. Consequently, the particle can be found at any position in the potential well. It can be shown, that realization of a particular position $x$ happens with a probability proportional to the *Boltzmann factor*:\n",
    "\n",
    "$$P(x) \\sim \\exp(-\\beta U(x)).$$\n",
    "\n",
    "As it usually is with probabilities, $\\int \\textrm{d} P(x) = 1$, hence we can convert the proportionality ($\\sim$) in the above relation into an equation. Let us define the *configuration integral* $Z$:\n",
    "$$Z = \\int \\textrm{d}x \\exp(-\\beta U(x)) \\quad \\Longrightarrow \\quad P(x) = \\frac{\\exp(-\\beta U(x))}{Z}.$$\n",
    "\n",
    "The ensemble average of any quantity $A(x)$ of the system is then defined as:\n",
    "\n",
    "$$\\langle A \\rangle = \\int \\textrm{d}x A(x) P(x) = \\frac{1}{Z} \\int \\textrm{d}x A(x) \\exp(-\\beta U(x)),$$\n",
    "\n",
    "so basically, just an average of the quantity over all states (positions) weighted by the probability of their realization.\n",
    "\n",
    "In this work-sheet, we will use Monte Carlo methods to estimate the ensemble average of the position of the particle in the well, $\\langle x \\rangle$; in other words, the ensemble average of the quantity $A(x) := x$.\n",
    "\n",
    "**To run a code in a cell, press `Enter + Shift` upon entering the cell. \n",
    "On your first reading, just run all of the cells with the default setting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np # numerical operations\n",
    "import time # stride for animations\n",
    "import scipy.integrate as sci_integral # trapezoidal integration\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "from IPython.display import clear_output # animations\n",
    "\n",
    "# constants\n",
    "x_min, x_max = -10, 10 # boundaries for the oscillator\n",
    "vx_min, vx_max = -4, 4 # boundaries for the visualization\n",
    "beta = 1.0 # 1/kT\n",
    "\n",
    "# define functions for later\n",
    "def potential(x, D0 = 1.0, a = 1.0, l = 0.9):\n",
    "    '''calculate the double well potential'''\n",
    "    U = ((D0 / a**4) * (x**2 - a**2)**2 + l*x)\n",
    "    return U\n",
    "\n",
    "def random_x(x_min = x_min, x_max = x_max):\n",
    "    '''generate a random float in the (x_min, x_max) range'''\n",
    "    return x_min + np.random.random() * (x_max - x_min)\n",
    "\n",
    "def move_metropolis(old_x, beta = beta, displacement = 0.5):\n",
    "    '''make MC move with Metropolis algorithm'''\n",
    "    E_old = potential(old_x) # energy of the old configuration\n",
    "    new_x = old_x + displacement*(np.random.random() - 0.5) # trial configuration with random displacement\n",
    "    E_new = potential(new_x) # energy of the new configuration\n",
    " \n",
    "    if E_new < E_old:\n",
    "        # if E_new < E_old, accept the new\n",
    "        return new_x\n",
    "    else:\n",
    "        # if E_new > E_old, accept with probability proportional to the boltzmann weight\n",
    "        boltzmann = np.exp(-beta * (E_new - E_old)) # Boltzmann factor\n",
    "        sample_probability = np.random.random() # sample probability to compare with the Boltzmann factor\n",
    "        if boltzmann > sample_probability:\n",
    "            return new_x\n",
    "        else:\n",
    "            return old_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Direct numerical integration\n",
    "\n",
    "For one-dimensional system with one particle and \"well-behaved\" potential, we can simply calculate the energies and associated Boltzmann factors at selected positions, and carry out the ensemble average integration numerically using trapezoid (or any other) rule. This is what we will do it in this section. \n",
    "\n",
    "We know, that $U(x)$ diverges for $x \\gg 0$ and $x \\ll 0$, hence $P(x) = 0$ there. Therefore, we will replace the integral by a discrete sum in a bounded interval of positions $x_0 < x < x_1$, in which we move by increments of $\\Delta x$. Hence\n",
    "$$Z = \\int \\textrm{d}x \\exp(-\\beta U(x)) \\approx \\sum_i \\Delta x \\cdot \\exp(-\\beta U(x_0 + i\\Delta x)),$$\n",
    "$$\\langle x \\rangle = \\frac{1}{Z} \\int \\textrm{d}x \\ x \\exp(-\\beta U(x)) \\approx \\dfrac{1}{Z} \\sum_i \\Delta x \\cdot (x_0 + i \\Delta x) \\cdot \\exp(-\\beta U(x_0 + i\\Delta x)).$$\n",
    "\n",
    "Execute the below cell to see the shape of the potential well, corresponding Boltzmann probabilities and the numerically calculated $\\langle x \\rangle$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of x and calculate the potential and Boltzmann probability\n",
    "xs = np.linspace(x_min, x_max, num = 10000) # positions; here we know that outside of [x_min, x_max], U(x) is very high, hence P(x) = 0\n",
    "Us = potential(xs) # energy\n",
    "ps = np.exp(-beta * Us) # Boltzmann factor\n",
    "Z = sci_integral.simps(ps, x = xs) # configuration integral\n",
    "ps /= Z # normalize the factor to get the probabilities\n",
    "\n",
    "# calculate the mean x by numerical integration\n",
    "true_mean = sci_integral.simps(ps * xs, x = xs)\n",
    "ps_range = ps.max() - ps.min()\n",
    "vis_range = [-ps_range * 0.05, ps_range*1.05] # probability scale for plotting\n",
    "\n",
    "# plot the potentials\n",
    "fig, ax = plt.subplots(1, 2, figsize = (8,4), gridspec_kw = {'width_ratios': [1,1]})\n",
    "for i in [0,1]:\n",
    "    ax[i].set_xlabel('position, $x$')\n",
    "    ax[i].set_xlim(vx_min, vx_max)\n",
    "ax[0].set_ylim(-1,5)\n",
    "ax[1].set_ylim(*vis_range)\n",
    "ax[0].set_ylabel('potential energy, $βU(x)$')\n",
    "ax[1].set_ylabel('probablity density, $P(x) = \\exp [-βU(x)]/Z$')\n",
    "ax[0].plot(xs,Us,)\n",
    "ax[1].plot(xs,ps,)\n",
    "ax[1].plot([true_mean,]*2, vis_range, linestyle = 'solid', color = 'black', linewidth = 2.0, label = 'mean')\n",
    "ax[1].set_title(\"$\\\\langle x_E \\\\rangle = {:.4f}$\".format(true_mean))\n",
    "fig.tight_layout()\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Monte Carlo\n",
    "\n",
    "Now we will use the Monte Carlo techniques to estimate the mean position of the particle, and we will compare it to the above method of *direct integration*.\n",
    "In such a simple one-dimensional system, the direct integration can be considered, in principle, (numerically) exact solution, which we will treat as a reference result, which we wish to reproduce with the Monte Carlo method.\n",
    "This exercise is supposed to demonstrate the main ideas of the Monte Carlo, but it does not really do a justice to its real strength.\n",
    "It might appear, from this exercise, that the Monte Carlo is more expensive and less accurate than the direct integration.\n",
    "The point is, however, that the direct integration is absolutely unfeasible for the multi-dimensional systems with many particles - there you have to use something different (f. e. Monte Carlo).\n",
    "\n",
    "In here, we will use the importance sampling Monte Carlo scheme with the Metropolis algorithm to sample positions of the particle. Note that the Metropolis algorithm already samples positions in accordance with the Boltzmann distributions, so any further reweighing is undesirable. The mean of the values of positions generated, should converge to the real ensemble average of this quantity.\n",
    "\n",
    "## 4.) Tasks\n",
    "\n",
    "Below, you can run a Monte Carlo code, which samples positions and accumulates them in the `time_series` array. To access the mean, you can use for example `time_series.mean()`. The code also provides a visualization: On the left-hand-side figure, you can see time series of the sampled positions. On the right-hand-side figure, you can see the emerging probability distribution generated by the time series of the sampled positions and the mean calculated from this time series. Both mean and distributions are compared to the \"exact\" results given by the above direct integration.\n",
    "\n",
    "1. run the Monte Carlo code with the default setting and observe which positions are being sampled the most. How do this positions relate to the shape of the potential well?\n",
    "1. observe the emerging probability distribution generated by the sampled positions. Visually verify that this probability profile indeed eventually converges to the \"exact\" (Boltzmann) distribution.\n",
    "1. explore the variance of the algorithm convergence: Run the Monte Carlo code with the default setting several times (the random seed is always automatically reset) and accumulate the mean positions into a set $X = \\{ \\langle x \\rangle_1, \\langle x \\rangle_2, \\dots, \\langle x \\rangle_M \\}$. Calculate the mean and the standard deviation over samples in $X$. Does a non-zero variance in the $X$ mean that the algorithm is incorrect?\n",
    "1. explore the rate of the algorithm convergence: Now repeat the step 3.) for different number of Monte Carlo steps. Plot the mean $\\pm$ standard deviation over $X$ as a function of Monte Carlo steps carried out. Interpreet the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_moves = 10000 # MC moves\n",
    "stride = 100 # period for visualization in units of MC moves\n",
    "wait_time = 0.2 # at the end of each visualization cycle, wait this many seconds - SET TO ZERO TO MAKE SIMULATIONS FASTER!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "time_series, current_x = np.zeros((N_moves+1)), 0\n",
    "\n",
    "# run the Monte Carlo\n",
    "for move in range(N_moves+1):\n",
    "    current_x = move_metropolis(current_x) # Monte Carlo move\n",
    "    time_series[move] = current_x # store the returned configuration\n",
    "\n",
    "    # visualization\n",
    "    if move % stride == 0 and move > 0:\n",
    "        mean = time_series[:move].mean()\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(1, 2, figsize = (18,6), gridspec_kw = {'width_ratios': [3,2]})\n",
    "        ax[0].set_xlabel('MC move')\n",
    "        ax[0].set_ylabel('position, $x$')\n",
    "        ax[1].set_xlabel('position, $x$')\n",
    "        ax[1].set_ylabel('probablity density, $P(x)$')\n",
    "        ax[0].set_xlim(0,N_moves)\n",
    "        ax[1].set_xlim(vx_min,vx_max)\n",
    "        ax[0].set_ylim(vx_min,vx_max)\n",
    "        ax[0].plot(time_series[:move], marker = '.', markersize = 1, linewidth = 0)\n",
    "        ax[1].set_ylim(-ps_range * 0.01, ps_range * 1.1)\n",
    "        ax[1].set_title(\"$\\\\langle x_E \\\\rangle = {:.4f}; \\\\ \\\\langle x_M \\\\rangle = {:.4f}$\".format(true_mean, mean))\n",
    "        ax[1].hist(time_series[:move], range = (vx_min, vx_max), bins = 100, density = True, label = 'Monte Carlo distribution')\n",
    "        ax[1].plot([true_mean, true_mean], [-ps_range * 0.01, ps_range * 1.1], linewidth = 3.0, color = 'pink', label = '\"exact mean\"')\n",
    "        ax[1].plot(xs, ps, linewidth = 2, markersize = 0, color = 'red', label = '\"exact distribution\"')\n",
    "        ax[1].plot([mean, mean], [-ps_range * 0.01, ps_range * 1.1], linewidth = 3.0, color = 'black', label = 'Monte Carlo mean')\n",
    "        ax[1].legend(loc = 'best')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        time.sleep(wait_time)\n",
    "        \n",
    "mean = time_series.mean()\n",
    "print(mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
